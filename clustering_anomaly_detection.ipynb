{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "**file name**: `clustering_anomaly_detection.py` or `clustering_anomaly_detection.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with the DBSCAN properties\n",
    "- Read up on the epsilon and min_samples arguments into DBSCAN at https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from random import randint\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "#used for DBclustering and scaling\n",
    "from sklearn.cluster import DBSCAN\n",
    "#using MinMax b'c Standard can have LESSTHAN 0, and Epsolon is 0-1 only\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import wrangle as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import host, user, password\n",
    "\n",
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_db_url(\"grocery_db\")\n",
    "\n",
    "sql = \"\"\"\n",
    "select *\n",
    "from grocery_customers\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster on subset of features\n",
    "grocery_milk_fresh = df[[\"Grocery\", \"Milk\",\"Fresh\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_milk_fresh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_milk_fresh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(grocery_milk_fresh)\n",
    "grocery_milk_fresh = scaler.transform(grocery_milk_fresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiment with altering the epsilon values (the eps argument holding the threshhold parameter). Run the models and visualize the results. What has changed? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbsc = DBSCAN(eps = .50, min_samples = 20).fit(grocery_milk_fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_columns = ['Grocery', 'Milk', 'Fresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's add the scaled value columns back onto the dataframe\n",
    "columns = list(df.columns)\n",
    "\n",
    "scaled_columns = [\"Scaled_\" + column for column in gmf_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the original dataframe\n",
    "original_df = df.copy()\n",
    "\n",
    "# Create a dataframe containing the scaled values\n",
    "scaled_df = pd.DataFrame(grocery_milk_fresh, columns=scaled_columns)\n",
    "\n",
    "# Merge the scaled and non-scaled values into one dataframe\n",
    "df = df.merge(scaled_df, on=df.index)\n",
    "df = df.drop(columns=['key_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dbsc.labels_\n",
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = labels\n",
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.labels==-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df.Grocery, df.Fresh, hue=df.labels)\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(df.Milk, df.Fresh, hue=df.labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 8))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "# plot the points\n",
    "ax.scatter(df.Fresh, df.Milk, df.Grocery,\n",
    "           c=df.labels, edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "ax.set_xlabel('Fresh')\n",
    "ax.set_ylabel('Milk')\n",
    "ax.set_zlabel('Grocery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.subplots_adjust(hspace=.7, wspace=.2)\n",
    "i = 1\n",
    "for x in range(10, 0, -1):\n",
    "    eps = 1/(11-x)\n",
    "    db = DBSCAN(eps=eps, min_samples=25).fit(grocery_milk_fresh)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    ax = fig.add_subplot(2, 5, i)\n",
    "    print(f'ùõÜ = {eps}')\n",
    "    sns.scatterplot(grocery_milk_fresh[:,0], grocery_milk_fresh[:,1], hue=[\"cluster-{}\".format(x) for x in labels])\n",
    "    i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Double the `min_samples` parameter. Run your model and visualize the results. Consider what changed and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.subplots_adjust(hspace=.7, wspace=.2)\n",
    "i = 1\n",
    "for x in range(4):\n",
    "    minsample = 20*x\n",
    "    db = DBSCAN(eps=0.1, min_samples=minsample).fit(grocery_milk_fresh)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    ax = fig.add_subplot(2, 5, i)\n",
    "    print(f'min_sample = {minsample}')\n",
    "    sns.scatterplot(grocery_milk_fresh[:,0], grocery_milk_fresh[:,1], hue=[\"cluster-{}\".format(x) for x in labels])\n",
    "    i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Clustering - DBSCAN\n",
    "Use DBSCAN to detect anomalies in other products from the customers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster on subset of features\n",
    "grocery_frozen_deli = df[[\"Grocery\", \"Frozen\",\"Delicassen\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_frozen_deli.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_frozen_deli.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfd_columns = ['Grocery', 'Frozen', 'Delicassen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "scaler = MinMaxScaler().fit(grocery_frozen_deli)\n",
    "grocery_frozen_deli = scaler.transform(grocery_frozen_deli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbsc = DBSCAN(eps = .10, min_samples = 20).fit(grocery_frozen_deli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's add the scaled value columns back onto the dataframe\n",
    "columns = list(df.columns)\n",
    "\n",
    "scaled_columns = [\"Scaled_\" + column for column in gfd_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the original dataframe\n",
    "original_df = df.copy()\n",
    "\n",
    "# Create a dataframe containing the scaled values\n",
    "scaled_df = pd.DataFrame(grocery_frozen_deli, columns=scaled_columns)\n",
    "\n",
    "# Merge the scaled and non-scaled values into one dataframe\n",
    "df = df.merge(scaled_df, on=df.index)\n",
    "df = df.drop(columns=['key_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.subplots_adjust(hspace=.7, wspace=.2)\n",
    "i = 1\n",
    "for x in range(10, 0, -1):\n",
    "    eps = 1/(11-x)\n",
    "    db = DBSCAN(eps=eps, min_samples=20).fit(grocery_frozen_deli)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    ax = fig.add_subplot(2, 5, i)\n",
    "    print(f'ùõÜ = {eps}')\n",
    "    sns.scatterplot(grocery_milk_fresh[:,0], grocery_milk_fresh[:,1], hue=[\"cluster-{}\".format(x) for x in labels])\n",
    "    i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 8))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "# plot the points\n",
    "ax.scatter(df.Delicassen, df.Frozen, df.Grocery,\n",
    "           c=df.labels, edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "ax.set_xlabel('Delicassen')\n",
    "ax.set_ylabel('Frozen')\n",
    "ax.set_zlabel('Grocery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Use DBSCAN to detect anomalies in: \n",
    "- number of bedrooms and \n",
    "- finished square feet of property \n",
    "\n",
    "for the filtered dataset you used in the `clustering project` (single unit properties with a logerror)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo = w.zillow17()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo = w.clean_zillow(zlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster on subset of features\n",
    "bdrmsqft = zlo[[\"bedrooms\", \"sqft\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdrmsqft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdrmsqft.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of column names from clustered subset of features: nu_df\n",
    "columns = bdrmsqft.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale and transform the DF\n",
    "scaler = MinMaxScaler().fit(bdrmsqft)\n",
    "bdrmsqft = scaler.transform(bdrmsqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdrmsqft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a DBSCAN object \n",
    "dbsc = DBSCAN(eps = .10, min_samples = 20).fit(bdrmsqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the scaled value columns back onto the dataframe\n",
    "scaled_columns = [\"Scaled_\" + column for column in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the original dataframe\n",
    "original_zlo = zlo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe containing the scaled values\n",
    "scaled_df = pd.DataFrame(bdrmsqft, columns=scaled_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the scaled and non-scaled values into one dataframe\n",
    "zlo = zlo.merge(scaled_df, on=zlo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo = zlo.drop(columns=['key_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract cluster labels and outliers \n",
    "labels = dbsc.labels_\n",
    "zlo['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(zlo.bathrooms, zlo.sqft, hue=df.labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densitybasedcluster(df, nu_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #create a list of column names from clustered subset of features: nu_df\n",
    "    columns = nu_df.columns.to_list()\n",
    "    \n",
    "    #scale and transform the DF\n",
    "    scaler = MinMaxScaler().fit(nu_df)\n",
    "    nu_df = scaler.transform(nu_df)\n",
    "    \n",
    "    #Construct a DBSCAN object \n",
    "    dbsc = DBSCAN(eps = .10, min_samples = 20).fit(nu_df)\n",
    "    \n",
    "    #add the scaled value columns back onto the dataframe\n",
    "    scaled_columns = [\"Scaled_\" + column for column in columns]\n",
    "    \n",
    "    # Save a copy of the original dataframe\n",
    "    original_df = df.copy()\n",
    "    \n",
    "    # Create a dataframe containing the scaled values\n",
    "    scaled_df = pd.DataFrame(nu_df, columns=scaled_columns)\n",
    "    \n",
    "    # Merge the scaled and non-scaled values into one dataframe\n",
    "    df = df.merge(scaled_df, on=df.index)\n",
    "    df = df.drop(columns=['key_0'])\n",
    "    \n",
    "    #extract cluster labels and outliers \n",
    "    labels = dbsc.labels_\n",
    "    df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densitybasedcluster(zlo, bdrmsqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdrmsqft.shape, zlo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bdrmsqft.index), len(zlo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
